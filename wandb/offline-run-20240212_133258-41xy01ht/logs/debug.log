2024-02-12 13:32:58,159 INFO    MainThread:77710 [wandb_setup.py:_flush():76] Current SDK version is 0.15.8
2024-02-12 13:32:58,159 INFO    MainThread:77710 [wandb_setup.py:_flush():76] Configure stats pid to 77710
2024-02-12 13:32:58,159 INFO    MainThread:77710 [wandb_setup.py:_flush():76] Loading settings from /Users/georgivitanov/.config/wandb/settings
2024-02-12 13:32:58,159 INFO    MainThread:77710 [wandb_setup.py:_flush():76] Loading settings from /Users/georgivitanov/Desktop/Thesis/causal-flows/wandb/settings
2024-02-12 13:32:58,160 INFO    MainThread:77710 [wandb_setup.py:_flush():76] Loading settings from environment variables: {'notebook_name': 'name_of_the_notebook'}
2024-02-12 13:32:58,160 INFO    MainThread:77710 [wandb_setup.py:_flush():76] Applying setup settings: {'_disable_service': False}
2024-02-12 13:32:58,160 INFO    MainThread:77710 [wandb_setup.py:_flush():76] Inferring run settings from compute environment: {'program_relpath': 'main.py', 'program': 'main.py'}
2024-02-12 13:32:58,160 INFO    MainThread:77710 [wandb_init.py:_log_setup():507] Logging user logs to /Users/georgivitanov/Desktop/Thesis/causal-flows/wandb/offline-run-20240212_133258-41xy01ht/logs/debug.log
2024-02-12 13:32:58,160 INFO    MainThread:77710 [wandb_init.py:_log_setup():508] Logging internal logs to /Users/georgivitanov/Desktop/Thesis/causal-flows/wandb/offline-run-20240212_133258-41xy01ht/logs/debug-internal.log
2024-02-12 13:32:58,160 INFO    MainThread:77710 [wandb_init.py:init():547] calling init triggers
2024-02-12 13:32:58,160 INFO    MainThread:77710 [wandb_init.py:init():554] wandb.init called with sweep_config: {}
config: {'device': 'cpu', 'root_dir': 'output_causal_nf/comparison_carefl', 'seed': 246, 'param_count': 1520, 'dataset__root': '../Data', 'dataset__name': 'simpson', 'dataset__sem_name': 'sym-prod', 'dataset__splits': [0.8, 0.1, 0.1], 'dataset__k_fold': 1, 'dataset__shuffle_train': True, 'dataset__single_split': False, 'dataset__loss': 'default', 'dataset__scale': 'default', 'dataset__num_samples': 25000, 'dataset__base_version': 1, 'dataset__add_noise': False, 'dataset__type': 'torch', 'dataset__use_edge_attr': False, 'model__name': 'causal_nf', 'model__layer_name': 'maf', 'model__net_name': 'mlp', 'model__dim_inner': [16, 16, 16], 'model__num_layers': -1, 'model__init': None, 'model__act': 'elu', 'model__dropout': 0.0, 'model__has_bn': False, 'model__distr_u': 'laplace', 'model__scale_base': False, 'model__shift_base': False, 'model__scale': False, 'model__parity': False, 'model__adjacency': False, 'model__base_to_data': False, 'model__base_distr': 'normal', 'model__learn_base': False, 'model__plot': False, 'model__latent_dim': 4, 'model__objective': 'elbo', 'model__beta': 1.0, 'model__distr_x': 'normal', 'model__lambda_': 0.01, 'gnn__num_layers_pre': 1, 'gnn__num_layers': 1, 'gnn__num_layers_post': 1, 'gnn__dim_inner': 64, 'gnn__heads': 1, 'gnn__stage_type': 'skipsum', 'gnn__aggregators': ['sum', 'mean', 'min', 'max', 'std'], 'gnn__scalers': ['identity', 'amplification', 'attenuation', 'linear', 'inverse_linear'], 'gnn__towers': 1, 'gnn__pre_layers': 1, 'gnn__post_layers': 1, 'gnn__eps': 0.0, 'gnn__train_eps': False, 'gnn2__num_layers_pre': 1, 'gnn2__num_layers': 1, 'gnn2__num_layers_post': 1, 'gnn2__dim_inner': 64, 'gnn2__heads': 1, 'gnn2__stage_type': 'skipsum', 'gnn2__aggregators': ['sum', 'mean', 'min', 'max', 'std'], 'gnn2__scalers': ['identity', 'amplification', 'attenuation', 'linear', 'inverse_linear'], 'gnn2__towers': 1, 'gnn2__pre_layers': 1, 'gnn2__post_layers': 1, 'gnn2__eps': 0.0, 'gnn2__train_eps': False, 'train__regularize': False, 'train__kl': 'forward', 'train__max_epochs': 1000, 'train__batch_size': 4000, 'train__num_workers': 0, 'train__limit_train_batches': None, 'train__limit_val_batches': None, 'train__auto_scale_batch_size': False, 'train__auto_lr_find': False, 'train__profiler': None, 'train__enable_progress_bar': False, 'train__max_time': '00:24:00:00', 'train__model_checkpoint': True, 'train__inference_mode': False, 'early_stopping__activate': False, 'early_stopping__min_delta': 0.0, 'early_stopping__patience': 100, 'early_stopping__verbose': False, 'optim__optimizer': 'adam', 'optim__base_lr': 0.001, 'optim__beta_1': 0.9, 'optim__beta_2': 0.999, 'optim__momentum': 0.0, 'optim__weight_decay': 0.0, 'optim__scheduler': 'plateau', 'optim__gamma': 0.99, 'optim__step_size': 100, 'optim__mode': 'min', 'optim__factor': 0.95, 'optim__patience': 60, 'optim__cooldown': 0}
2024-02-12 13:32:58,160 INFO    MainThread:77710 [wandb_init.py:init():596] starting backend
2024-02-12 13:32:58,160 INFO    MainThread:77710 [wandb_init.py:init():600] setting up manager
2024-02-12 13:32:58,163 INFO    MainThread:77710 [backend.py:_multiprocessing_setup():106] multiprocessing start_methods=spawn,fork,forkserver, using: spawn
2024-02-12 13:32:58,165 INFO    MainThread:77710 [wandb_init.py:init():606] backend started and connected
2024-02-12 13:32:58,183 INFO    MainThread:77710 [wandb_init.py:init():697] updated telemetry
2024-02-12 13:32:58,232 INFO    MainThread:77710 [wandb_init.py:init():730] communicating run to backend with 60.0 second timeout
2024-02-12 13:32:58,238 INFO    MainThread:77710 [wandb_init.py:init():781] starting run threads in backend
2024-02-12 13:33:00,510 INFO    MainThread:77710 [wandb_run.py:_console_start():2159] atexit reg
2024-02-12 13:33:00,510 INFO    MainThread:77710 [wandb_run.py:_redirect():2014] redirect: wrap_raw
2024-02-12 13:33:00,510 INFO    MainThread:77710 [wandb_run.py:_redirect():2079] Wrapping output streams.
2024-02-12 13:33:00,510 INFO    MainThread:77710 [wandb_run.py:_redirect():2104] Redirects installed.
2024-02-12 13:33:00,511 INFO    MainThread:77710 [wandb_init.py:init():822] run started, returning control to user process
2024-02-12 13:55:34,703 WARNING MsgRouterThr:77710 [router.py:message_loop():77] message_loop has been closed
